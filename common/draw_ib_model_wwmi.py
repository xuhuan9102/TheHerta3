import struct
import numpy
import os




from ..utils.config_utils import ConfigUtils
from ..utils.collection_utils import *
from ..config.main_config import *
from ..utils.json_utils import *
from ..utils.timer_utils import TimerUtils
from ..utils.format_utils import Fatal
from ..utils.obj_utils import *
from ..utils.shapekey_utils import ShapeKeyUtils
from ..utils.log_utils import LOG

from .extracted_object import ExtractedObject, ExtractedObjectHelper
from ..base.obj_data_model import ObjDataModel
from ..base.component_model import ComponentModel
from ..base.d3d11_gametype import D3D11GameType
from ..base.m_draw_indexed import M_DrawIndexed

from ..config.import_config import ImportConfig
from .obj_buffer_model import ObjBufferModel

from .branch_model import BranchModel

from ..config.properties_wwmi import Properties_WWMI


# 配置常量（按项目实际情况调整）
VG_SLOTS = 4           # 每顶点写多少个 VG id（与 Blend.buf 的槽数一致）
BLOCK_SIZE = 512       # forward/reverse block 大小（WWMI 默认为 512）
REMAPP_SKIP_THRESHOLD = 256  # 超过多少个 VG 才启用 Remap（WWMI 默认为 256）


# 辅助函数
def unique_preserve_order(seq):
    seen = set()
    out = []
    for x in seq:
        if x not in seen:
            seen.add(x)
            out.append(x)
    return out

def collect_component_mesh_data(obj, vg_slots=VG_SLOTS):
    """
    输入：一个 component 的已合并对象（component_obj），返回：
    - vertex_count
    - index_data (list of vertex indices, flattened triangles)
    - vg_ids (list of lists) 每顶点 vg_slots 个 uint (原始 group indices)
    - vg_weights (list of lists) 每顶点对应权重 0..255
    """
    mesh = ObjUtils.get_mesh_evaluate_from_obj(obj)
    mesh.calc_loop_triangles()

    # index_data: flatten all triangles' vertex indices
    index_list = []
    for tri in mesh.loop_triangles:
        index_list.extend(list(tri.vertices))
    index_data = index_list
    vertex_count = len(mesh.vertices)

    # Build per-vertex vg id and weights, fixed vg_slots
    vg_ids = [[0]*vg_slots for _ in range(vertex_count)]
    vg_weights = [[0]*vg_slots for _ in range(vertex_count)]

    for vi, v in enumerate(mesh.vertices):
        slot = 0
        # v.groups: Blender's collection of vertex group weights for this vertex
        for g in v.groups:
            if slot >= vg_slots:
                break
            # g.group is the group index (int), g.weight is 0..1
            vg_ids[vi][slot] = int(g.group)
            vg_weights[vi][slot] = int(round(max(0.0, min(1.0, g.weight)) * 255))
            slot += 1

    return vertex_count, index_data, vg_ids, vg_weights

def build_remap_blocks_per_component(index_layout, index_data, vg_ids, vg_weights):
    """
    根据 component 的 index_layout（list）和 per-vertex vg 数据生成 forward/reverse block。
    这里我们假设 index_layout 的每一项对应一个 component 在合并大对象里的 index count。
    但是在本示例中我们将为每个 component 单独调用 collect_component_mesh_data，
    即 index_layout 通常为 [len(index_data)]（单组件内部）。
    返回：
    - remapped_counts: list of N per component (int)
    - forward_all: list of uint16 concatenated forward blocks
    - reverse_all: list of uint16 concatenated reverse blocks
    """
    remapped_counts = []
    forward_all = []
    reverse_all = []

    idx_offset = 0
    for idx_count in index_layout:
        segment = index_data[idx_offset: idx_offset + idx_count]
        idx_offset += idx_count
        # get unique vertex indices (preserve order)
        vertex_ids = unique_preserve_order(segment)
        if not vertex_ids:
            remapped_counts.append(0)
            continue

        # collect vg ids + weights for those vertex_ids
        obj_vg_ids = []
        obj_vg_weights = []
        for vid in vertex_ids:
            # guard out-of-range
            if vid < 0 or vid >= len(vg_ids):
                continue
            row_ids = vg_ids[vid]
            row_ws = vg_weights[vid]
            # flatten row
            for i in range(len(row_ids)):
                obj_vg_ids.append(int(row_ids[i]))
                obj_vg_weights.append(int(row_ws[i]))

        # Quick skip: if all ids < REMAPP_SKIP_THRESHOLD => no remap needed
        if not obj_vg_ids:
            remapped_counts.append(0)
            continue
        try:
            if max(obj_vg_ids) < REMAPP_SKIP_THRESHOLD:
                remapped_counts.append(0)
                continue
        except ValueError:
            remapped_counts.append(0)
            continue

        # filter by weight > 0
        non_zero_ids = [orig for orig, w in zip(obj_vg_ids, obj_vg_weights) if w > 0]
        if not non_zero_ids:
            remapped_counts.append(0)
            continue

        unique_ids = unique_preserve_order(non_zero_ids)
        # again check threshold
        if max(unique_ids) < REMAPP_SKIP_THRESHOLD:
            remapped_counts.append(0)
            continue

        # guard: ids must be < BLOCK_SIZE to index reverse array
        if max(unique_ids) >= BLOCK_SIZE:
            # policy: skip remap for this component and warn
            print(f'WARNING: component has VG id >= {BLOCK_SIZE}, skipping remap for that component.')
            remapped_counts.append(0)
            continue

        N = len(unique_ids)
        remapped_counts.append(N)

        # build forward block and reverse block of length BLOCK_SIZE
        forward_block = [0] * BLOCK_SIZE
        for i, orig in enumerate(unique_ids):
            forward_block[i] = int(orig)

        reverse_block = [0] * BLOCK_SIZE
        for i, orig in enumerate(unique_ids):
            reverse_block[orig] = int(i)

        forward_all.extend(forward_block)
        reverse_all.extend(reverse_block)

    return remapped_counts, forward_all, reverse_all

def write_uint16_file(path, values):
    with open(path, 'wb') as f:
        for v in values:
            f.write(struct.pack('<H', int(v) & 0xFFFF))

def write_uint32_file(path, values):
    with open(path, 'wb') as f:
        for v in values:
            f.write(struct.pack('<I', int(v) & 0xFFFFFFFF))

def write_vertex_vg_file(path, all_vg_ids, vg_slots=VG_SLOTS):
    """
    all_vg_ids: list of per-vertex lists (concatenated across components in the same order as they will be joined)
    """
    with open(path, 'wb') as f:
        for row in all_vg_ids:
            row2 = (list(row) + [0]*vg_slots)[:vg_slots]
            for id_val in row2:
                f.write(struct.pack('<H', int(id_val) & 0xFFFF))

# ---------------------------------------------------------
# 集成示例：在你的组件循环之后调用（伪调用）
# 假设 components_objs 是你在循环里得到的每个 component_obj 列表（顺序与后续 join 顺序一致）
# ---------------------------------------------------------

def export_blendremap_for_components(components_objs, out_dir):
    os.makedirs(out_dir, exist_ok=True)

    # 存放所有组件的 per-vertex vg ids（按组件顺序串接，确保与 join 操作顺序相同）
    concatenated_vg_ids = []

    # per-component concatenated forward/reverse blocks and counts
    all_remapped_counts = []
    all_forward_blocks = []
    all_reverse_blocks = []

    # For each component object, collect its data and compute remap (component-level)
    for comp_obj in components_objs:
        vertices_count, index_data, vg_ids, vg_weights = collect_component_mesh_data(comp_obj, vg_slots=VG_SLOTS)

        # append per-vertex vg ids to global list (in same order as comp_obj vertices)
        concatenated_vg_ids.extend(vg_ids)

        # For a single component object, index_layout is a single-element [len(index_data)]
        index_layout = [len(index_data)]
        remapped_counts, forward_all, reverse_all = build_remap_blocks_per_component(index_layout, index_data, vg_ids, vg_weights)

        # extend global lists
        all_remapped_counts.extend(remapped_counts)
        all_forward_blocks.extend(forward_all)
        all_reverse_blocks.extend(reverse_all)

    # Write files

    write_vertex_vg_file(os.path.join(out_dir, 'BlendRemapVertexVG.buf'), concatenated_vg_ids, vg_slots=VG_SLOTS)
    print(f'Wrote BlendRemapVertexVG.buf ({len(concatenated_vg_ids)} vertices, {VG_SLOTS} slots each)')

    if all_forward_blocks:
        write_uint16_file(os.path.join(out_dir, 'BlendRemapForward.buf'), all_forward_blocks)
        write_uint16_file(os.path.join(out_dir, 'BlendRemapReverse.buf'), all_reverse_blocks)
        write_uint32_file(os.path.join(out_dir, 'BlendRemapLayout.buf'), all_remapped_counts)  # 可选，便于 debug
        print(f'Wrote BlendRemapForward.buf and BlendRemapReverse.buf with {len(all_forward_blocks)//BLOCK_SIZE} blocks')
    else:
        print('No remap blocks required (all components have VG ids < 256).')

    return {
        'vertex_vg_count': len(concatenated_vg_ids),
        'blocks_count': len(all_forward_blocks)//BLOCK_SIZE,
        'counts': all_remapped_counts
    }

class DrawIBModelWWMI:
    '''
    这个代表了一个DrawIB的Mod导出模型
    Mod导出可以调用这个模型来进行业务逻辑部分
    每个游戏的DrawIBModel都是不同的，但是一部分是可以复用的
    (例如WWMI就有自己的一套DrawIBModel) 
    '''

    # 通过default_factory让每个类的实例的变量分割开来，不再共享类的静态变量
    def __init__(self,draw_ib:str,branch_model:BranchModel):
        # (1) 读取工作空间下的Config.json来设置当前DrawIB的别名
        draw_ib_alias_name_dict = ConfigUtils.get_draw_ib_alias_name_dict()
        self.draw_ib = draw_ib
        self.draw_ib_alias = draw_ib_alias_name_dict.get(draw_ib,draw_ib)

        # (2) 读取工作空间中配置文件的配置项
        self.import_config = ImportConfig(draw_ib=self.draw_ib)
        self.d3d11GameType:D3D11GameType = self.import_config.d3d11GameType
        # 读取WWMI专属配置
        self.extracted_object:ExtractedObject = ExtractedObjectHelper.read_metadata(GlobalConfig.path_extract_gametype_folder(draw_ib=self.draw_ib,gametype_name=self.d3d11GameType.GameTypeName)  + "Metadata.json")

        '''
        这里是要得到每个Component对应的obj_data_model列表
        '''
        self.ordered_obj_data_model_list:list[ObjDataModel] = branch_model.get_obj_data_model_list_by_draw_ib(draw_ib=draw_ib)
        
        # (3) 组装成特定格式？
        self._component_model_list:list[ComponentModel] = []
        self.component_name_component_model_dict:dict[str,ComponentModel] = {}

        for part_name in self.import_config.part_name_list:
            print("part_name: " + part_name)
            component_obj_data_model_list = []
            for obj_data_model in self.ordered_obj_data_model_list:
                if part_name == str(obj_data_model.component_count):
                    component_obj_data_model_list.append(obj_data_model)
                    print("obj_data_model: " + obj_data_model.obj_name)

            component_model = ComponentModel(component_name="Component " + part_name,final_ordered_draw_obj_model_list=component_obj_data_model_list)
            
            self._component_model_list.append(component_model)
            self.component_name_component_model_dict[component_model.component_name] = component_model
        LOG.newline()


        # (4) 根据之前解析集合架构的结果，读取obj对象内容到字典中
        self.mesh_vertex_count = 0 # 每个DrawIB都有总的顶点数，对应CategoryBuffer里的顶点数。

        # (5) 对所有obj进行融合，得到一个最终的用于导出的临时obj
        self.merged_object = self.build_merged_object(
            extracted_object=self.extracted_object
        )

        # (6) 填充每个obj的drawindexed值，给每个obj的属性统计好，后面就能直接用了。
        self.obj_name_drawindexed_dict:dict[str,M_DrawIndexed] = {} 
        for comp in self.merged_object.components:
            for comp_obj in comp.objects:
                draw_indexed_obj = M_DrawIndexed()
                draw_indexed_obj.DrawNumber = str(comp_obj.index_count)
                draw_indexed_obj.DrawOffsetIndex = str(comp_obj.index_offset)
                draw_indexed_obj.AliasName = comp_obj.name
                self.obj_name_drawindexed_dict[comp_obj.name] = draw_indexed_obj
        
        # (7) 填充到component_name为key的字典中，方便后续操作
        for component_model in self._component_model_list:
            new_ordered_obj_model_list = []
            for obj_model in component_model.final_ordered_draw_obj_model_list:
                obj_model.drawindexed_obj = self.obj_name_drawindexed_dict[obj_model.obj_name]
                new_ordered_obj_model_list.append(obj_model)
            component_model.final_ordered_draw_obj_model_list = new_ordered_obj_model_list
            self.component_name_component_model_dict[component_model.component_name] = component_model
        
        # (8) 选中当前融合的obj对象，计算得到ib和category_buffer，以及每个IndexId对应的VertexId
        merged_obj = self.merged_object.object

        merged_obj.name
        
        TimerUtils.Start("构建ObjBufferModel")
        obj_buffer_model = ObjBufferModel(d3d11_game_type=self.d3d11GameType,obj_name=merged_obj.name)
        TimerUtils.End("构建ObjBufferModel")

        # TODO 如果Merged架构下，顶点组数量超过了255，则必须使用Remap技术
        # 在这里遍历获取每个Component的obj列表，然后对这些obj进行统计，统计BLENDINDICES和BLENDWEIGHTS
        # 生成BlendRemapForward.buf中的内容
        # 每个Component 每512个数字为一组，有几个Component就有几组 格式：R16_UINT
        # 对应的位数就是局部顶点索引
        # 对应的位上的内容就是原始的顶点组索引
        
        # 需要一个方法，能够获取指定obj的所有的d3d11Element内容。
        # 其次就是可能要考虑到先声明数据类型，后进行执行的问题，比如WWMI就是把所有的数据类型提前全部声明好
        # 最后需要的时候只执行一次就把所有的内容都拿到了，本质上是数据类型设计的比较好。

        # 因为MergedObj已经全部合并在一起了
        # 也许我们可以更改一下合并的流程，让它们先把每个Component的合并在一起，得到一个Obj列表
        # 此时就可以根据这个obj列表，获取其属性，然后决定是否要使用remap技术
        # 然后记录在mergedobj的属性里，然后再把这几个单独component的合并在一起
        # 最后得到mergedobj，同时也把生成BlendRemapForward.buf和BlendRemapReverse.buf的信息获取到了
        # 最后再根据mergedobj来获取生成BlendRemapVertexVG.buf的信息
        # 大概就是这个思路，所以build_merged_obj这个流程还需要深入理解并且做一些修改，才能实现remap技术
        

        # 写出到文件
        self.write_out_index_buffer(ib=obj_buffer_model.ib)
        self.write_out_category_buffer(category_buffer_dict=obj_buffer_model.category_buffer_dict)
        self.write_out_shapekey_buffer(merged_obj=merged_obj, index_vertex_id_dict=obj_buffer_model.index_vertex_id_dict)

        # 删除临时融合的obj对象
        bpy.data.objects.remove(merged_obj, do_unlink=True)


    def write_out_index_buffer(self,ib):
        buf_output_folder = GlobalConfig.path_generatemod_buffer_folder()

        packed_data = struct.pack(f'<{len(ib)}I', *ib)
        with open(buf_output_folder + self.draw_ib + "-Component1.buf", 'wb') as ibf:
            ibf.write(packed_data) 

    def write_out_category_buffer(self,category_buffer_dict):
        __categoryname_bytelist_dict = {} 
        for category_name in self.d3d11GameType.OrderedCategoryNameList:
            if category_name not in __categoryname_bytelist_dict:
                __categoryname_bytelist_dict[category_name] =  category_buffer_dict[category_name]
            else:
                existing_array = __categoryname_bytelist_dict[category_name]
                buffer_array = category_buffer_dict[category_name]

                # 确保两个数组都是NumPy数组
                existing_array = numpy.asarray(existing_array)
                buffer_array = numpy.asarray(buffer_array)

                # 使用 concatenate 连接两个数组，确保传递的是一个序列（如列表或元组）
                concatenated_array = numpy.concatenate((existing_array, buffer_array))

                # 更新字典中的值
                __categoryname_bytelist_dict[category_name] = concatenated_array

        # 顺便计算一下步长得到总顶点数
        position_stride = self.d3d11GameType.CategoryStrideDict["Position"]
        position_bytelength = len(__categoryname_bytelist_dict["Position"])
        self.mesh_vertex_count = int(position_bytelength/position_stride)

        buf_output_folder = GlobalConfig.path_generatemod_buffer_folder()
            
        for category_name, category_buf in __categoryname_bytelist_dict.items():
            buf_path = buf_output_folder + self.draw_ib + "-" + category_name + ".buf"
             # 将 list 转换为 numpy 数组
            # category_array = numpy.array(category_buf, dtype=numpy.uint8)
            with open(buf_path, 'wb') as ibf:
                category_buf.tofile(ibf)

    def write_out_shapekey_buffer(self,merged_obj,index_vertex_id_dict):
        buf_output_folder = GlobalConfig.path_generatemod_buffer_folder()

        self.shapekey_offsets = []
        self.shapekey_vertex_ids = []
        self.shapekey_vertex_offsets = []

        # (11) 拼接ShapeKey数据
        if merged_obj.data.shape_keys is None or len(getattr(merged_obj.data.shape_keys, 'key_blocks', [])) == 0:
            print(f'No shapekeys found to process!')
        else:
            shapekey_offsets,shapekey_vertex_ids,shapekey_vertex_offsets_np = ShapeKeyUtils.extract_shapekey_data(merged_obj=merged_obj,index_vertex_id_dict=index_vertex_id_dict)
            # extract_shapekey_data_v2
            # shapekey_offsets,shapekey_vertex_ids,shapekey_vertex_offsets_np = ShapeKeyUtils.extract_shapekey_data_v2(mesh=mesh,index_vertex_id_dict=index_vertex_id_dict)

            self.shapekey_offsets = shapekey_offsets
            self.shapekey_vertex_ids = shapekey_vertex_ids
            self.shapekey_vertex_offsets = shapekey_vertex_offsets_np

            # 鸣潮的ShapeKey三个Buffer的导出
            if len(self.shapekey_offsets) != 0:
                with open(buf_output_folder + self.draw_ib + "-" + "ShapeKeyOffset.buf", 'wb') as file:
                    for number in self.shapekey_offsets:
                        # 假设数字是32位整数，使用'i'格式符
                        # 根据实际需要调整数字格式和相应的格式符
                        data = struct.pack('i', number)
                        file.write(data)
            
            if len(self.shapekey_vertex_ids) != 0:
                with open(buf_output_folder + self.draw_ib + "-" + "ShapeKeyVertexId.buf", 'wb') as file:
                    for number in self.shapekey_vertex_ids:
                        # 假设数字是32位整数，使用'i'格式符
                        # 根据实际需要调整数字格式和相应的格式符
                        data = struct.pack('i', number)
                        file.write(data)
            
            if len(self.shapekey_vertex_offsets) != 0:
                # 将列表转换为numpy数组，并改变其数据类型为float16
                float_array = numpy.array(self.shapekey_vertex_offsets, dtype=numpy.float32).astype(numpy.float16)
                with open(buf_output_folder + self.draw_ib + "-" + "ShapeKeyVertexOffset.buf", 'wb') as file:
                    float_array.tofile(file)

    def build_merged_object(self,extracted_object:ExtractedObject):
        '''
        extracted_object 用于读取配置
        
        此方法用于为当前DrawIB构建MergedObj对象
        '''
        print("build_merged_object::")

        # 1.Initialize components
        components = []
        for component in extracted_object.components: 
            components.append(
                MergedObjectComponent(
                    objects=[],
                    index_count=0,
                )
            )
        
        # 2.import_objects_from_collection
        # 这里是获取所有的obj，需要用咱们的方法来进行集合架构的遍历获取所有的obj
        # Nico: 添加缓存机制，一个obj只处理一次
        workspace_collection = bpy.context.collection

        processed_obj_name_list:list[str] = []
        for component_model in self._component_model_list:
            component_count = str(component_model.component_name)[10:]
            print("ComponentCount: " + component_count)

            # 这里减去1是因为我们的Compoennt是从1开始的,但是WWMITools的逻辑是从0开始的
            component_id = int(component_count) - 1 
            print("component_id: " + str(component_id))
            
            for obj_data_model in component_model.final_ordered_draw_obj_model_list:
                obj_name = obj_data_model.obj_name
                print("obj_name: " + obj_name)
                
                # Nico: 如果已经处理过这个obj，则跳过
                if obj_name in processed_obj_name_list:
                    print(f"Skipping already processed object: {obj_name}")
                    continue
                processed_obj_name_list.append(obj_name)

                obj = ObjUtils.get_obj_by_name(obj_name)

                # 复制出一个TEMP_为前缀的obj出来
                # 这里我们设置collection为None，不链接到任何集合中，防止干扰
                temp_obj = ObjUtils.copy_object(bpy.context, obj, name=f'TEMP_{obj.name}', collection=workspace_collection)

                # 添加到当前component的objects列表中，添加的是复制出来的TEMP_的obj
                try:
                    components[component_id].objects.append(TempObject(
                        name=obj.name,
                        object=temp_obj,
                    ))
                except Exception as e:
                    print(f"Error appending object to component: {e}")

        print("准备临时对象::")
        # 3.准备临时对象
        index_offset = 0
        # 这里的component_id是从0开始的，务必注意
        for component_id, component in enumerate(components):
            
            # 排序以确保obj的命名符合规范而不是根据集合中的位置来进行
            component.objects.sort(key=lambda x: x.name)

            for temp_object in component.objects:
                temp_obj = temp_object.object
                print("Processing temp_obj: " + temp_obj.name)

                # Remove muted shape keys
                if Properties_WWMI.ignore_muted_shape_keys() and temp_obj.data.shape_keys:
                    print("Removing muted shape keys for object: " + temp_obj.name)
                    muted_shape_keys = []
                    for shapekey_id in range(len(temp_obj.data.shape_keys.key_blocks)):
                        shape_key = temp_obj.data.shape_keys.key_blocks[shapekey_id]
                        if shape_key.mute:
                            muted_shape_keys.append(shape_key)
                    for shape_key in muted_shape_keys:
                        print("Removing shape key: " + shape_key.name)
                        temp_obj.shape_key_remove(shape_key)

                # Apply all modifiers to temporary object
                if Properties_WWMI.apply_all_modifiers():
                    print("Applying all modifiers for object: " + temp_obj.name)
                    with OpenObject(bpy.context, temp_obj) as obj:
                        selected_modifiers = [modifier.name for modifier in get_modifiers(obj)]
                        ShapeKeyUtils.apply_modifiers_for_object_with_shape_keys(bpy.context, selected_modifiers, None)

                # Triangulate temporary object, this step is crucial as export supports only triangles
                ObjUtils.triangulate_object(bpy.context, temp_obj)

                # Handle Vertex Groups
                vertex_groups = ObjUtils.get_vertex_groups(temp_obj)

                # Remove ignored or unexpected vertex groups
                if Properties_WWMI.import_merged_vgmap():
                    print("Remove ignored or unexpected vertex groups for object: " + temp_obj.name)
                    # Exclude VGs with 'ignore' tag or with higher id VG count from Metadata.ini for current component
                    total_vg_count = sum([component.vg_count for component in extracted_object.components])
                    ignore_list = [vg for vg in vertex_groups if 'ignore' in vg.name.lower() or vg.index >= total_vg_count]
                else:
                    # Exclude VGs with 'ignore' tag or with higher id VG count from Metadata.ini for current component
                    extracted_component = extracted_object.components[component_id]
                    total_vg_count = len(extracted_component.vg_map)
                    ignore_list = [vg for vg in vertex_groups if 'ignore' in vg.name.lower() or vg.index >= total_vg_count]
                remove_vertex_groups(temp_obj, ignore_list)

                # Rename VGs to their indicies to merge ones of different components together
                for vg in ObjUtils.get_vertex_groups(temp_obj):
                    vg.name = str(vg.index)

                # Calculate vertex count of temporary object
                temp_object.vertex_count = len(temp_obj.data.vertices)
                # Calculate index count of temporary object, IB stores 3 indices per triangle
                temp_object.index_count = len(temp_obj.data.polygons) * 3
                # Set index offset of temporary object to global index_offset
                temp_object.index_offset = index_offset
                # Update global index_offset
                index_offset += temp_object.index_count
                # Update vertex and index count of custom component
                component.vertex_count += temp_object.vertex_count
                component.index_count += temp_object.index_count

        # 上面的内容为每个component里的每个obj都移除了不必要的顶点组，以及统计好了vertex_count和index_count
        # TODO 感觉可以再遍历一次来获取ReMap技术所需的信息




        # build_merged_object:
        drawib_merged_object = []
        drawib_vertex_count, drawib_index_count = 0, 0

        component_obj_list = []
        for component in components:
            
            component_merged_object:list[bpy.types.Object] = []

            # for temp_object in component.objects:
            #     drawib_merged_object.append(temp_object.object)
            # 改为先把component的obj组合在一起，得到当前component的obj
            # 然后就能获取每个component是否使用remap技术的信息了
            # 然后最后再融合到drawib级别的mergedobj中，也不影响最终结果
            for temp_object in component.objects:
                component_merged_object.append(temp_object.object)

            ObjUtils.join_objects(bpy.context, component_merged_object)

            component_obj = component_merged_object[0]
            component_obj_list.append(component_obj)
            
            drawib_merged_object.append(component_obj)

            drawib_vertex_count += component.vertex_count
            drawib_index_count += component.index_count
            
        # component_obj_list 写出
        # components_objs 是你在循环中得到的每个 component_obj 的列表（顺序与 drawib_merged_object 一致）
        summary = export_blendremap_for_components(component_obj_list, GlobalConfig.path_generatemod_buffer_folder())
        print('BlendRemap export summary:', summary)

        ObjUtils.join_objects(bpy.context, drawib_merged_object)

        obj = drawib_merged_object[0]

        ObjUtils.rename_object(obj, 'TEMP_EXPORT_OBJECT')

        deselect_all_objects()
        select_object(obj)
        set_active_object(bpy.context, obj)

        mesh = ObjUtils.get_mesh_evaluate_from_obj(obj)

        drawib_merged_object = MergedObject(
            object=obj,
            mesh=mesh,
            components=components,
            vertex_count=len(obj.data.vertices),
            index_count=len(obj.data.polygons) * 3,
            vg_count=len(ObjUtils.get_vertex_groups(obj)),
            shapekeys=MergedObjectShapeKeys(),
        )

        if drawib_vertex_count != drawib_merged_object.vertex_count:
            raise ValueError('vertex_count mismatch between merged object and its components')

        if drawib_index_count != drawib_merged_object.index_count:
            raise ValueError('index_count mismatch between merged object and its components')
        
        LOG.newline()
        return drawib_merged_object
    

